{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0,1,1,1]).reshape(-1, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0.]), array([0., 0.])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = (2, 3, 2)\n",
    "\n",
    "weigths = [np.random.normal(0, 1, (a, b)) for a, b in np.c_[layers[1:], layers[:-1]]]\n",
    "biases = [np.zeros(a) for a in layers[1:]]\n",
    "\n",
    "a = X[1]\n",
    "\n",
    "for W, b in np.c_[weigths, biases]:\n",
    "    a = np.dot(W, a) + b\n",
    "    \n",
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48336431],\n",
       "       [0.46278483],\n",
       "       [0.45645622],\n",
       "       [0.43252677]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "_activation = {'sigmoid': sigmoid,\n",
    "               'relu': relu}\n",
    "\n",
    "\n",
    "def MSE(y, y_hat):\n",
    "    return np.mean(np.square(y - y_hat))\n",
    "\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, layers, activation='sigmoid', random_state=3141):\n",
    "        np.random.seed(random_state)\n",
    "        self.layers = layers\n",
    "        self.weigths = [np.random.normal(0, 1, (a, b)) for a, b in np.c_[self.layers[1:], self.layers[:-1]]]\n",
    "        self.biases = [np.zeros(a).reshape(-1, 1) for a in self.layers[1:]]\n",
    "        self.h = _activation[activation]\n",
    "                \n",
    "    def predict(self, X):\n",
    "        for W, b in np.c_[self.weigths, self.biases]:\n",
    "            X = self.h(np.dot(W, X.T) + b).T\n",
    "        return X\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        error = np.square(y - y_hat)\n",
    "        \n",
    "        idx = np.arange(y.size)\n",
    "        np.random.shuffle(idx)\n",
    "        \n",
    "        for layer in self. layers:\n",
    "            break\n",
    "    \n",
    "    \n",
    "nn = NeuralNetwork((2, 3, 1))\n",
    "nn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1]]),\n",
       " array([[0.5       , 0.5       , 0.5       ],\n",
       "        [0.31961772, 0.4128964 , 0.65819559],\n",
       "        [0.55669738, 0.75858657, 0.38161232],\n",
       "        [0.37103947, 0.68846255, 0.54303156]]),\n",
       " array([[0.48336431],\n",
       "        [0.46278483],\n",
       "        [0.45645622],\n",
       "        [0.43252677]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def d_sigmoid(y):\n",
    "    dy = y * (1 - y)\n",
    "    return dy\n",
    "\n",
    "y = np.array([0, 0.25, 0.5, 0.75]).reshape(-1 ,1)\n",
    "\n",
    "w = nn.weigths\n",
    "b = nn.biases\n",
    "layers = nn.layers\n",
    "\n",
    "y_hat = nn.predict(X)\n",
    "y_hat\n",
    "\n",
    "# Forward propagation\n",
    "L = [X]\n",
    "for W, b in np.c_[nn.weigths, nn.biases]:\n",
    "    L.append(nn.h(np.dot(W, L[-1].T) + b).T)\n",
    "\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00505119],\n",
       "       [0.00505119],\n",
       "       [0.99494905],\n",
       "       [0.99494905]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n",
    "    \n",
    "# input dataset\n",
    "X = np.array([  [0,1],\n",
    "                [0,1],\n",
    "                [1,0],\n",
    "                [1,0] ])\n",
    "    \n",
    "# output dataset            \n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "synapse_0 = 2*np.random.random((2,1)) - 1\n",
    "\n",
    "for _ in range(10000):\n",
    "\n",
    "    # forward propagation\n",
    "    layer_0 = X\n",
    "    layer_1 = sigmoid(np.dot(layer_0,synapse_0))\n",
    "\n",
    "    # how much did we miss?\n",
    "    layer_1_error = layer_1 - y\n",
    "\n",
    "    # multiply how much we missed by the \n",
    "    # slope of the sigmoid at the values in l1\n",
    "    layer_1_delta = layer_1_error * sigmoid_output_to_derivative(layer_1)\n",
    "    synapse_0_derivative = np.dot(layer_0.T,layer_1_delta)\n",
    "\n",
    "    # update weights\n",
    "    synapse_0 -= synapse_0_derivative\n",
    "\n",
    "\n",
    "layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.75552917],\n",
       "       [-0.75552917],\n",
       "       [ 0.22776912],\n",
       "       [ 0.22776912]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X, NeuralNetwork((2, 1)).weigths[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.28316618],\n",
       "       [-5.28311816]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synapse_0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
